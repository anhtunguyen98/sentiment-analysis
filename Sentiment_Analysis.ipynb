{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCVNFshhFnCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyvi\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "from pyvi import ViTokenizer\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf8qzFlIQhVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  \n",
        "  text=gensim.utils.simple_preprocess(text)\n",
        "  text=' '.join(text)\n",
        "  return ViTokenizer.tokenize(text)\n",
        "def pre_process(list_text):\n",
        "  return [clean_text(text) for text in list_text]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNE4-AvRRtp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('/content/drive/My Drive/data/train.csv',sep='\\t')\n",
        "Text_train=train_df.text.values\n",
        "Label_train=train_df.label.values\n",
        "Text_train=pre_process(Text_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSLJXFLpSIWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = [len(text) for text in Text_train]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(num_words, 100)\n",
        "plt.xlabel('Số từ trong câu')\n",
        "plt.ylabel('Tần số')\n",
        "plt.axis([0, 600, 0, 5000])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPZ8F-kkSuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences=[[word for word in text.split(\" \")] for text in Text_train]\n",
        "sentences.append(['UNK','PAD'])\n",
        "\n",
        "word_model=gensim.models.Word2Vec(sentences=sentences,size=200,min_count=1,window=5)\n",
        "print(word_model.wv.syn0)\n",
        "\n",
        "print(word_model.wv.syn0.shape)\n",
        "\n",
        "print(word_model.wv.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7c9exNcTuFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.functional import softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUUn9LXEczf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_model=KeyedVectors.load_word2vec_format('/content/drive/My Drive/data/word_vector')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuhAvz-DU_Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBBEDING_DIM=word_model.wv.syn0.shape[1]\n",
        "VOCAB_SIZE=word_model.wv.syn0.shape[0]\n",
        "MAX_LENGTH=200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx3m_XjZUpWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Sentiment_Analysic(torch.nn.Module):\n",
        "#   def __init__(self,vocab_size,embedding_dim,num_labels):\n",
        "#     super().__init__()\n",
        "#     self.embedding=torch.nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim)\n",
        "#     self.bilstm=torch.nn.LSTM(bidirectional=True,input_size=embedding_dim,hidden_size=512,num_layers=2,batch_first=True)\n",
        "#     # self.dropout=torch.nn.Dropout(0.5)\n",
        "#     self.linear1=torch.nn.Linear(512,128)\n",
        "#     self.linear2=torch.nn.Linear(128,num_labels)\n",
        "#   def forward(self,input):\n",
        "#     output=self.embedding(input)\n",
        "#     output,(hidden,cell)=self.bilstm(output)\n",
        "    \n",
        "#     output=self.linear1(hidden[-1])\n",
        "#     output=self.linear2(output)\n",
        "#     # output=self.dropout(output)\n",
        "#     return softmax(output,dim=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBCvMZRbaANq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model=Sentiment_Analysic(vocab_size=VOCAB_SIZE,embedding_dim=EMBBEDING_DIM,num_labels=2)\n",
        "# # model.embedding.weight.data.copy_(torch.tensor(word_model.wv.syn0))\n",
        "# model=torch.load('/content/drive/My Drive/data/Sentiment_Analysis_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdDhIy2l2o2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=[[word for word in sent.split(' ')] for sent in Text_train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2ywey2x6Sh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=word_model.wv.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USSLaooQ1e0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train=pad_sequences([[vocab.get(word).index for word in sent] for sent in X_train],value=vocab.get('PAD').index,maxlen=MAX_LENGTH,truncating='post',padding='post',dtype='long')\n",
        "\n",
        "X_train,X_val,y_train,y_val=train_test_split(X_train,Label_train,test_size=0.1,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5opvxmYji0mH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "class Cnn_Sentiment_Analysis(torch.nn.Module):\n",
        "    def __init__(self, vocab_size,embedding_dim ,window_sizes=(3, 4, 5)):\n",
        "        super(Cnn_Sentiment_Analysis, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, 128, [window_size, embedding_dim], padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(128 * len(window_sizes), 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)           # [B, T, E]\n",
        "\n",
        "        # Apply a convolution + max pool layer for each window size\n",
        "        x = torch.unsqueeze(x, 1)       # [B, C, T, E] Add a channel dim.\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = F.relu(conv(x))        # [B, F, T, 1]\n",
        "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)            # [B, F, window]\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)       # [B, F * window]\n",
        "        logits = self.fc(x)             # [B, class]\n",
        "\n",
        "        # Prediction\n",
        "        probs = F.softmax(logits,dim=-1)       # [B, class]\n",
        "        \n",
        "\n",
        "        return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emax339RkRfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Cnn_Sentiment_Analysis(vocab_size=VOCAB_SIZE,embedding_dim=EMBBEDING_DIM)\n",
        "model.embedding.weight.data.copy_(torch.tensor(word_model.wv.syn0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0tl0luB4LAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import SGD\n",
        "optimizer=SGD(model.parameters(),lr=5e-2)\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXahOCtPACzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader,TensorDataset,RandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXSM2mnv9_Da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=torch.tensor(X_train)\n",
        "y_train=torch.tensor(y_train)\n",
        "train_data=TensorDataset(X_train,y_train)\n",
        "train_sample=RandomSampler(train_data)\n",
        "train_dataloader=DataLoader(train_data,sampler=train_sample,batch_size=64)\n",
        "\n",
        "X_val=torch.tensor(X_val)\n",
        "y_val=torch.tensor(y_val)\n",
        "val_data=TensorDataset(X_val,y_val)\n",
        "val_sample=RandomSampler(val_data)\n",
        "val_dataloader=DataLoader(val_data,sampler=val_sample,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8njH3Jp4A44y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install seqeval\n",
        "from seqeval.metrics import f1_score,accuracy_score\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "epochs=5\n",
        "from tqdm import tqdm, trange\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnAzu3DABLsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_loss,val_loss=[],[]\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "      batch = tuple(t.cuda() for t in batch)\n",
        "      x,y=batch\n",
        "      model.zero_grad()\n",
        "\n",
        "      output=model(x)\n",
        "      loss=criterion(output,y)\n",
        "      total_loss+=loss.item()\n",
        "      loss.backward()\n",
        "      # clip_grad_norm_(parameters=model.parameters(), max_norm=1)\n",
        "      optimizer.step()\n",
        "  avg_train_loss = total_loss / len(train_dataloader)\n",
        "  tr_loss.append(avg_train_loss)\n",
        "  print('train loss: {}'.format(avg_train_loss))\n",
        "  model.eval()\n",
        "  eval_loss=0\n",
        "  eval_acc=0\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    batch = tuple(t.cuda() for t in batch)\n",
        "    x,y=batch\n",
        "    with torch.no_grad():\n",
        "      output=model(x)\n",
        "    loss=criterion(output,y)\n",
        "    eval_loss+=loss.item()\n",
        "    output=output.detach().cpu().numpy()\n",
        "    acc=accuracy_score(output.argmax(axis=1),y.to('cpu').numpy())\n",
        "    eval_acc+=acc\n",
        "  avg_val_loss=eval_loss/len(val_dataloader)\n",
        "  avg_val_acc=eval_acc/len(val_dataloader)\n",
        "  print('validation loss: {}'.format(avg_val_loss))\n",
        "  print('validation accuracy : {}'.format(avg_val_acc))\n",
        "  val_loss.append(avg_val_loss)\n",
        "\n",
        "\n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4XO0HiMEgeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model,'/content/drive/My Drive/data/Cnn_Sentiment_Analysis_model.pt',_use_new_zipfile_serialization=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axqo71KQF69w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpEFZFkpGH02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_model.wv.save_word2vec_format('/content/drive/My Drive/data/word_vector')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvLqxCAoGoTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test=pd.read_csv('/content/drive/My Drive/data/test.csv',sep='\\t')\n",
        "id=df_test['id'].values\n",
        "Text_test=df_test['text'].values\n",
        "\n",
        "Text_test=Text_test.astype('str')\n",
        "Text_test=pre_process(Text_test)\n",
        "\n",
        "test_sentences = [[word for word in text.split(\" \")] for text in Text_test]\n",
        "\n",
        "\n",
        "X_test=[]\n",
        "for sentence in test_sentences:\n",
        "  x=[]\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      x.append(vocab.get('UNK').index)\n",
        "    else:\n",
        "      x.append(vocab.get(word).index)\n",
        "  X_test.append(x)\n",
        "test_ids = pad_sequences([[word for word in sent] for sent in X_test],\n",
        "                            value=vocab.get('PAD').index, maxlen=MAX_LENGTH, truncating='post', padding='post',\n",
        "                            dtype='long')\n",
        "\n",
        "y_predict=[]\n",
        "\n",
        "for input_id in test_ids:\n",
        "  input_id=torch.tensor([input_id],dtype=torch.long)\n",
        "  with torch.no_grad():\n",
        "    output=model(input_id.cuda())\n",
        "  output=output.detach().cpu().numpy()\n",
        "  y_predict.append(output.argmax(axis=1)[0])\n",
        "  # print(output.argmin(axis=1)[0])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtPd8P71j-qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "df_test['label']=np.array(y_predict).astype(np.int)\n",
        "df_test['id']=id\n",
        "df_test[[\"id\",\"label\"]].to_csv(\"/content/drive/My Drive/data/submission.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5gTZJ1xwTbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_sentences[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQbnk_Rqwd-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}